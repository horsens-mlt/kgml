############ Modelling ############

###   Includes following: 
#     1. XGBoost 
#     2. Logistic Regression
#     3. Support Vector Machines 
#     4. ADABoost
#     5. Gradient Boosting

### 1. XGBoost 
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

# Fitting Models:  
model_smo = XGBClassifier()
model_smo.fit(x_train_smo, y_train_smo, verbose=False)

model_ada = XGBClassifier()
model_ada.fit(x_train_ada, y_train_ada, verbose=False)

model_us = XGBClassifier()
model_us.fit(x_train_us, y_train_us, verbose=False)

# Creating Predictions: 
pred_smo=model_smo.predict(x_test)
print('Accuracy of XGBoost classifier - SMO on test set: {:.3f}'.format(accuracy_score(y_test, pred_smo)))

pred_ada=model_ada.predict(x_test)
print('Accuracy of XGBoost classifier - ADA on test set: {:.3f}'.format(accuracy_score(y_test, pred_ada)))

pred_us=model_us.predict(x_test_us)
print('Accuracy of XGBoost classifier - US on test set: {:.3f}'.format(accuracy_score(y_test_us, pred_us)))

# Confusion matrices
print('Confusion matrix - XGBoost with Smote:')
print(confusion_matrix(y_test,pred_smo))

print('\n','Confusion matrix - XGBoost with Adasyn:')
print(confusion_matrix(y_test,pred_ada))

print('\n','Confusion matrix - XGBoost with UnderSampling:')
print(confusion_matrix(y_test_us,pred_us))

# Accuracy measures: 
from sklearn.metrics import classification_report
print('Performance Measures - XGBoost with Smote:')
print(classification_report(y_test, pred_smo)) 

print('\n','Performance Measures - XGBoost with Adasyn:')
print(classification_report(y_test,pred_ada))

print('\n','Performance Measures - XGBoost with Adasyn:')
print(classification_report(y_test_us,pred_us))

#AUC/ROC curves: 

from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve

print('ROC/AUC - XGBoost with SMOTE:')
logit_roc_auc = roc_auc_score(y_test, model_smo.predict(x_test))
fpr, tpr, thresholds = roc_curve(y_test, model_smo.predict_proba(x_test)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='XGBoost with SMOTE (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()

print('ROC/AUC - XGBoost with ADASYN:')
logit_roc_auc = roc_auc_score(y_test, model_ada.predict(x_test))
fpr, tpr, thresholds = roc_curve(y_test, model_ada.predict_proba(x_test)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='XGBoost with ADASYN (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()

print('ROC/AUC - XGBoost with US:')
logit_roc_auc = roc_auc_score(y_test_us, model_us.predict(x_test_us))
fpr, tpr, thresholds = roc_curve(y_test_us, model_us.predict_proba(x_test_us)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='XGBoost with US (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()

### 2. Logistic Regression 
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

# Fitting Models:  
log_smo = LogisticRegression()
log_smo.fit(x_train_smo, y_train_smo)
   
log_ada = LogisticRegression()
log_ada.fit(x_train_ada, y_train_ada)

log_us = LogisticRegression()
log_us.fit(x_train_us, y_train_us) 

# Creating Predictions: 
y_pred_smo = log_smo.predict(x_test)
print('Accuracy of logistic regression classifier - SMO on test set: {:.3f}'.format(accuracy_score(y_test, y_pred_smo)))

y_pred_ada = log_ada.predict(x_test)
print('Accuracy of logistic regression classifier - ADA on test set: {:.3f}'.format(accuracy_score(y_test, y_pred_ada)))

y_pred_us = log_us.predict(x_test_us)
print('Accuracy of logistic regression classifier - US on test set: {:.3f}'.format(accuracy_score(y_test_us, y_pred_us)))

# Confusion matrices
print('Confusion matrix - Logistic Regression with Smote:')
print(confusion_matrix(y_test, y_pred_smo))

print('\n','Confusion matrix - Logistic Regression with Adasyn:')
print(confusion_matrix(y_test, y_pred_ada))

print('\n','Confusion matrix - Logistic Regression with UnderSampling:')
print(confusion_matrix(y_test_us, y_pred_us))

# Accuracy measures: 
from sklearn.metrics import classification_report
print('Performance Measures - XGBoost with Smote:')
print(classification_report(y_test, y_pred_smo)) 

print('\n','Performance Measures - XGBoost with Adasyn:')
print(classification_report(y_test,y_pred_ada))

print('\n','Performance Measures - XGBoost with Adasyn:')
print(classification_report(y_test_us,y_pred_us))

#AUC/ROC curves: 

from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve

print('Logistic Regression with SMOTE:')
logit_roc_auc = roc_auc_score(y_test, log_smo.predict(x_test))
fpr, tpr, thresholds = roc_curve(y_test, log_smo.predict_proba(x_test)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='Logistic Regression with SMOTE (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()

print('Logistic Regression with ADASYN:')
logit_roc_auc = roc_auc_score(y_test, log_ada.predict(x_test))
fpr, tpr, thresholds = roc_curve(y_test, log_ada.predict_proba(x_test)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='Logistic Regression with ADASYN (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()

print('Logistic Regression with US:')
logit_roc_auc = roc_auc_score(y_test_us, model_us.predict(x_test_us))
fpr, tpr, thresholds = roc_curve(y_test_us, log_us.predict_proba(x_test_us)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='Logistic Regression with US (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()

### 3. Support Vector Machines 
from sklearn import svm
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

# Fitting Models
svc_smo = svm.SVC(gamma='scale', probability = True)
svc_smo.fit(x_train_smo, y_train_smo)

svc_ada = svm.SVC(gamma='scale', probability = True)
svc_ada.fit(x_train_ada, y_train_ada)

svc_us = svm.SVC(gamma='scale', probability = True)
svc_us.fit(x_train_us, y_train_us)

# Creating predictions 
svc_pred_smo = svc_smo.predict(x_test)
print('Accuracy of SVM classifier - SMO on test set: {:.3f}'.format(accuracy_score(y_test, svc_pred_smo)))

svc_pred_ada = svc_ada.predict(x_test)
print('Accuracy of SVM classifier - ADA on test set: {:.3f}'.format(accuracy_score(y_test, svc_pred_ada)))

svc_pred_us = svc_us.predict(x_test_us)
print('Accuracy of SVM classifier - US on test set: {:.3f}'.format(accuracy_score(y_test_us, svc_pred_us)))

# Confusion matrices
print('Confusion matrix - Support Vector Machine with Smote:')
print(confusion_matrix(y_test, svc_pred_smo))

print('\n','Confusion matrix - Support Vector Machine with Adasyn:')
print(confusion_matrix(y_test, svc_pred_ada))

print('\n','Confusion matrix - Support Vector Machine with UnderSampling:')
print(confusion_matrix(y_test_us, svc_pred_us))

# Accuracy measures: 
from sklearn.metrics import classification_report
print('Performance Measures - XGBoost with Smote:')
print(classification_report(y_test, svc_pred_smo)) 

print('\n','Performance Measures - XGBoost with Adasyn:')
print(classification_report(y_test,svc_pred_ada))

print('\n','Performance Measures - XGBoost with Adasyn:')
print(classification_report(y_test_us,svc_pred_us))

#AUC/ROC curves: 

from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve

print('SVMs with SMOTE :')
logit_roc_auc = roc_auc_score(y_test, svc_smo.predict(x_test))
fpr, tpr, thresholds = roc_curve(y_test, svc_smo.predict_proba(x_test)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='SVMs with SMOTE (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()

print('SVMs with ADASYN:')
logit_roc_auc = roc_auc_score(y_test, svc_ada.predict(x_test))
fpr, tpr, thresholds = roc_curve(y_test, svc_ada.predict_proba(x_test)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='SVMs with ADASYN (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()

print('SVMs with US:')
logit_roc_auc = roc_auc_score(y_test_us, svc_us.predict(x_test_us))
fpr, tpr, thresholds = roc_curve(y_test_us, svc_us.predict_proba(x_test_us)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='SVMs with US (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()

### 4. ADABoost

# Adaboost: 

# Fitting Models & creating predictions: 
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import AdaBoostClassifier

clf_smo = AdaBoostClassifier(n_estimators=100)
ada_smo = clf_smo.fit(x_train_smo,y_train_smo)
ada_pred_smo = ada_smo.predict(x_test)
print('Accuracy of ADABoost classifier - SMO on test set: {:.2f}'.format(ada_smo.score(x_test, y_test)))

clf_ada = AdaBoostClassifier(n_estimators=100)
ada_ada = clf_ada.fit(x_train_ada,y_train_ada)
ada_pred_ada = ada_ada.predict(x_test)
print('Accuracy of ADABoost classifier - ADA on test set: {:.2f}'.format(ada_ada.score(x_test, y_test)))

clf_us = AdaBoostClassifier(n_estimators=100)
ada_us = clf_us.fit(x_train_us,y_train_us)
ada_pred_us = ada_us.predict(x_test_us)
print('Accuracy of ADABoost classifier - US on test set: {:.2f}'.format(ada_ada.score(x_test_us, y_test_us)))

# Confusion matrices
print('Confusion matrix - ADABoost with Smote:')
print(confusion_matrix(y_test, ada_pred_smo))

print('\n','Confusion matrix - ADABoost with Adasyn:')
print(confusion_matrix(y_test, ada_pred_ada))

print('\n','Confusion matrix - ADABoost with UnderSampling:')
print(confusion_matrix(y_test_us, ada_pred_us))

# Accuracy measures: 
from sklearn.metrics import classification_report
print('Performance Measures - ADABoost with Smote:')
print(classification_report(y_test, ada_pred_smo)) 

print('\n','Performance Measures - ADABoost with Adasyn:')
print(classification_report(y_test,ada_pred_ada))

print('\n','Performance Measures - ADABoost with Adasyn:')
print(classification_report(y_test_us,ada_pred_us))

#AUC/ROC curves: 

from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve

print('ADABoost with SMOTE :')
logit_roc_auc = roc_auc_score(y_test, ada_smo.predict(x_test))
fpr, tpr, thresholds = roc_curve(y_test, ada_smo.predict_proba(x_test)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='ADABoost with SMOTE (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()

print('ADABoost with ADASYN:')
logit_roc_auc = roc_auc_score(y_test, ada_ada.predict(x_test))
fpr, tpr, thresholds = roc_curve(y_test, ada_ada.predict_proba(x_test)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='ADABoost with ADASYN (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()

print('ADABoost with US:')
logit_roc_auc = roc_auc_score(y_test_us, ada_us.predict(x_test_us))
fpr, tpr, thresholds = roc_curve(y_test_us, ada_us.predict_proba(x_test_us)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='ADABoost with US (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()

### 5. Gradient Boosting 

# Training & creating predictions: 
from sklearn.ensemble import GradientBoostingClassifier
gbc_smo = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(x_train_smo, y_train_smo)
gbc_pred_smo = gbc_smo.predict(x_test)
print('Accuracy of GB classifier - SMO on test set: {:.2f}'.format(gbc_smo.score(x_test, y_test)))

gbc_ada = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(x_train_ada, y_train_ada)
gbc_pred_ada = gbc_ada.predict(x_test)
print('Accuracy of GB classifier - ADA on test set: {:.2f}'.format(gbc_ada.score(x_test, y_test)))

gbc_us = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(x_train_us, y_train_us)
gbc_pred_us = gbc_us.predict(x_test_us)
print('Accuracy of GB classifier - US on test set: {:.2f}'.format(gbc_us.score(x_test_us, y_test_us)))

# Confusion matrices
print('Confusion matrix - GB with Smote:')
print(confusion_matrix(y_test, gbc_pred_smo))

print('\n','Confusion matrix - GB with Adasyn:')
print(confusion_matrix(y_test, gbc_pred_ada))

print('\n','Confusion matrix - GB with UnderSampling:')
print(confusion_matrix(y_test_us, gbc_pred_us))

# Accuracy measures: 
from sklearn.metrics import classification_report
print('Performance Measures - GB with Smote:')
print(classification_report(y_test, gbc_pred_smo)) 

print('\n','Performance Measures - GB with Adasyn:')
print(classification_report(y_test,gbc_pred_ada))

print('\n','Performance Measures - GB with Adasyn:')
print(classification_report(y_test_us,gbc_pred_us))

#AUC/ROC curves: 

from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve

print('GB with SMOTE :')
logit_roc_auc = roc_auc_score(y_test, gbc_smo.predict(x_test))
fpr, tpr, thresholds = roc_curve(y_test, gbc_smo.predict_proba(x_test)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='GB with SMOTE (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()

print('GB with ADASYN:')
logit_roc_auc = roc_auc_score(y_test, gbc_ada.predict(x_test))
fpr, tpr, thresholds = roc_curve(y_test, gbc_ada.predict_proba(x_test)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='GB with ADASYN (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()

print('GB with US:')
logit_roc_auc = roc_auc_score(y_test_us, gbc_us.predict(x_test_us))
fpr, tpr, thresholds = roc_curve(y_test_us, gbc_us.predict_proba(x_test_us)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='GB with US (area = %0.2f)' % logit_roc_auc)
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Log_ROC')
plt.show()
